{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/kunai-3txk/student-compe/blob/main/PSP_EDA.ipynb",
      "authorship_tag": "ABX9TyPEriXyZhgEQumADkPnBxXG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunai-3txk/student-compe/blob/main/PSP_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ref\n",
        "https://www.kaggle.com/code/kentaro7/beginner-lgbm\n",
        "\n",
        "https://www.kaggle.com/code/mohammad2012191/lgbm-early-stopping-lb-0-670"
      ],
      "metadata": {
        "id": "Vxc2e9wRnR-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import"
      ],
      "metadata": {
        "id": "xnZJ743IdfZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polars\n",
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wiyoj4t-ey_w",
        "outputId": "c550aee7-212f-46e5-a002-f78cc09d3fcb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting polars\n",
            "  Downloading polars-0.16.14-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from polars) (4.5.0)\n",
            "Installing collected packages: polars\n",
            "Successfully installed polars-0.16.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp39-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.4.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (4.39.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (23.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.15.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DRcm6iVbb-ym"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GroupKFold, KFold\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from itertools import combinations\n",
        "import math\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_rows\", 200)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "from lightgbm.sklearn import LGBMRegressor\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "qCJQPbQY0Fo7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "Ll0Cbi-reTZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class paths:\n",
        "    # kaggle環境ならTrue\n",
        "    if 'KAGGLE_URL_BASE' in set(os.environ.keys()):\n",
        "        common_path = \"/kaggle/input/amp-parkinsons-disease-progression-prediction\"\n",
        "    \n",
        "    # colaboratory環境ならTrue\n",
        "    if 'COLAB_GPU' in set(os.environ.keys()):\n",
        "        common_path = \"/content/drive/MyDrive/PSP/\"\n",
        "\n",
        "    SAMPLE_SUBMISSION = common_path + \"sample_submission.csv\"\n",
        "    TRAIN = common_path + \"train.csv\"\n",
        "    TRAIN_LABELS = common_path + \"train_labels.csv\"\n",
        "    TEST = common_path + \"test.csv\"\n",
        "    OUTPUT = common_path"
      ],
      "metadata": {
        "id": "n1BbvP7feUet"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# defnition"
      ],
      "metadata": {
        "id": "-KlePzYlkjC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "CEuavv67kiPb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "TnI6GD0CdjrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = pd.read_csv(paths.TRAIN_LABELS)\n",
        "train_ori  =  reduce_mem_usage(pd.read_csv(paths.TRAIN))\n",
        "test_ori =  pd.read_csv(paths.TEST)\n",
        "sample_submission =  pd.read_csv(paths.SAMPLE_SUBMISSION)"
      ],
      "metadata": {
        "id": "Ye4ccxIudlIq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets['session'] = targets.session_id.apply(lambda x: int(x.split('_')[0]))\n",
        "targets['q'] = targets.session_id.apply(lambda x: int(x.split('_')[-1][1:]))\n",
        "\n",
        "train = train_ori.copy()\n",
        "test = test_ori.copy()\n",
        "train.drop([\"fullscreen\",\"hq\",\"music\"],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "d0I4aV1fzGKp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ubaOJlXmzGEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#train"
      ],
      "metadata": {
        "id": "BaiWi3SqnEHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train.describe()\n",
        "#train.info()"
      ],
      "metadata": {
        "id": "SW9_Wx5fkf0Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "bUpKekeFrK1F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineer(data):\n",
        "\n",
        "  data[\"elapsed_time\"].fillna(data[\"elapsed_time\"].mean())\n",
        "  data[\"elapsed_time\"] = np.log(data[\"elapsed_time\"]).round(3)\n",
        "  data[\"elapsed_time\"] = data[\"elapsed_time\"].replace([np.inf, -np.inf], np.nan)\n",
        "  data[\"elapsed_time\"].fillna(2.25,inplace=True)\n",
        "\n",
        "  le = LabelEncoder()\n",
        "\n",
        "  data[\"event_name\"] = le.fit_transform(data[\"event_name\"])\n",
        "  data[\"name\"] = le.fit_transform(data[\"name\"])\n",
        "  data[\"page\"] = data[\"page\"].fillna(-1)\n",
        "  data[\"page\"] = data[\"page\"].astype(int)\n",
        "  data[\"room_coor_x\"].fillna(0,inplace=True)\n",
        "  data[\"room_coor_y\"].fillna(0,inplace=True)\n",
        "  data[\"screen_coor_x\"].fillna(0,inplace=True)\n",
        "  data[\"screen_coor_y\"].fillna(0,inplace=True)\n",
        "  data[\"hover_duration\"].fillna(0,inplace=True)\n",
        "\n",
        "  data.reset_index(drop=True)\n",
        "\n",
        "  KEYS = ['session_id','level_group']\n",
        "  NUMS = ['elapsed_time','room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "  CATS = ['event_name','name','fqid', 'room_fqid', 'text_fqid']\n",
        "\n",
        "  data_byn = data.groupby(KEYS)[NUMS].agg([\"max\",\"min\",\"mean\",\"std\"])\n",
        "  data_byn.columns = ['_'.join(col) for col in data_byn.columns]\n",
        "  data_byn = data_byn.reset_index()\n",
        "\n",
        "  data_byc = data.groupby(KEYS)[CATS].agg('nunique')\n",
        "  data_byc = data_byc.reset_index()\n",
        "  #train_byc = train_byc.set_index(\"session_id\")\n",
        "\n",
        "  ret_data =  data_byn.merge(data_byc,on=['session_id','level_group'])\n",
        "\n",
        "  ret_data =  ret_data.reset_index(drop=True)\n",
        "  ret_data = ret_data.set_index(\"session_id\")\n",
        "\n",
        "  #print('byn shape:',data_byn.shape,'byc shape:',data_byc.shape,'ret_df shape:',ret_data.shape)\n",
        "  return ret_data"
      ],
      "metadata": {
        "id": "3stO_vx2wFe2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = feature_engineer(train)\n",
        "print(df_train.shape)\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "8qkjUzwdw5Y7",
        "outputId": "bec361b0-4af3-4b85-a238-3b7c92ae41ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(35337, 30)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  level_group  elapsed_time_max  elapsed_time_min  \\\n",
              "session_id                                                          \n",
              "20090312431273200         0-4            12.180             2.250   \n",
              "20090312431273200       13-22            14.057            13.637   \n",
              "20090312431273200        5-12            13.121            12.308   \n",
              "20090312433251036         0-4            12.362             2.250   \n",
              "20090312433251036       13-22            15.155            13.978   \n",
              "\n",
              "                   elapsed_time_mean  elapsed_time_std  room_coor_x_max  \\\n",
              "session_id                                                                \n",
              "20090312431273200          11.000733          1.229232            955.5   \n",
              "20090312431273200          13.847905          0.122041           1164.0   \n",
              "20090312431273200          12.759943          0.231607           1111.0   \n",
              "20090312433251036          10.901266          1.601088            934.5   \n",
              "20090312433251036          14.675087          0.349149           1234.0   \n",
              "\n",
              "                   room_coor_x_min  room_coor_x_mean  room_coor_x_std  \\\n",
              "session_id                                                              \n",
              "20090312431273200          -1013.5          7.269531       388.166178   \n",
              "20090312431273200          -1874.0       -121.687500       601.817476   \n",
              "20090312431273200           -808.0         12.804688       337.958386   \n",
              "20090312433251036          -1112.0        -78.625000       431.685473   \n",
              "20090312433251036          -1887.0        -24.750000       475.227565   \n",
              "\n",
              "                   room_coor_y_max  room_coor_y_min  room_coor_y_mean  \\\n",
              "session_id                                                              \n",
              "20090312431273200           416.00          -307.75         -67.50000   \n",
              "20090312431273200           473.25          -849.00        -151.25000   \n",
              "20090312431273200           419.50          -331.00         -51.28125   \n",
              "20090312433251036           441.00          -518.50         -50.18750   \n",
              "20090312433251036           433.00          -845.00        -115.00000   \n",
              "\n",
              "                   room_coor_y_std  screen_coor_x_max  screen_coor_x_min  \\\n",
              "session_id                                                                 \n",
              "20090312431273200       126.746080              843.0                0.0   \n",
              "20090312431273200       226.191270              859.0                0.0   \n",
              "20090312431273200       131.170538              872.0                0.0   \n",
              "20090312433251036       151.585043              875.0                0.0   \n",
              "20090312433251036       217.663468              878.0                0.0   \n",
              "\n",
              "                   screen_coor_x_mean  screen_coor_x_std  screen_coor_y_max  \\\n",
              "session_id                                                                    \n",
              "20090312431273200               424.0         232.526128              639.0   \n",
              "20090312431273200               413.0         257.076718              659.0   \n",
              "20090312431273200               404.5         237.050205              640.0   \n",
              "20090312433251036               335.0         259.713553              639.0   \n",
              "20090312433251036               372.5         296.259769              657.0   \n",
              "\n",
              "                   screen_coor_y_min  screen_coor_y_mean  screen_coor_y_std  \\\n",
              "session_id                                                                    \n",
              "20090312431273200                0.0              362.25         133.609168   \n",
              "20090312431273200                0.0              354.00         134.654423   \n",
              "20090312431273200                0.0              339.00         162.603835   \n",
              "20090312433251036                0.0              346.75         148.604281   \n",
              "20090312433251036                0.0              312.25         194.826328   \n",
              "\n",
              "                   hover_duration_max  hover_duration_min  \\\n",
              "session_id                                                  \n",
              "20090312431273200              7899.0                 0.0   \n",
              "20090312431273200              4750.0                 0.0   \n",
              "20090312431273200              4183.0                 0.0   \n",
              "20090312433251036              5567.0                 0.0   \n",
              "20090312433251036             22351.0                 0.0   \n",
              "\n",
              "                   hover_duration_mean  hover_duration_std  event_name  name  \\\n",
              "session_id                                                                     \n",
              "20090312431273200           115.854546          842.377807          10     3   \n",
              "20090312431273200            57.852383          393.094761          10     3   \n",
              "20090312431273200            98.243240          506.186455          10     3   \n",
              "20090312433251036            79.352516          575.094634          11     4   \n",
              "20090312433251036           139.966843          921.308692          11     6   \n",
              "\n",
              "                   fqid  room_fqid  text_fqid  \n",
              "session_id                                     \n",
              "20090312431273200    30          7         17  \n",
              "20090312431273200    49         12         35  \n",
              "20090312431273200    39         11         24  \n",
              "20090312433251036    22          6         11  \n",
              "20090312433251036    73         16         43  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6dbdec3-af9d-4ff9-807e-e4e6dd0ada31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_group</th>\n",
              "      <th>elapsed_time_max</th>\n",
              "      <th>elapsed_time_min</th>\n",
              "      <th>elapsed_time_mean</th>\n",
              "      <th>elapsed_time_std</th>\n",
              "      <th>room_coor_x_max</th>\n",
              "      <th>room_coor_x_min</th>\n",
              "      <th>room_coor_x_mean</th>\n",
              "      <th>room_coor_x_std</th>\n",
              "      <th>room_coor_y_max</th>\n",
              "      <th>room_coor_y_min</th>\n",
              "      <th>room_coor_y_mean</th>\n",
              "      <th>room_coor_y_std</th>\n",
              "      <th>screen_coor_x_max</th>\n",
              "      <th>screen_coor_x_min</th>\n",
              "      <th>screen_coor_x_mean</th>\n",
              "      <th>screen_coor_x_std</th>\n",
              "      <th>screen_coor_y_max</th>\n",
              "      <th>screen_coor_y_min</th>\n",
              "      <th>screen_coor_y_mean</th>\n",
              "      <th>screen_coor_y_std</th>\n",
              "      <th>hover_duration_max</th>\n",
              "      <th>hover_duration_min</th>\n",
              "      <th>hover_duration_mean</th>\n",
              "      <th>hover_duration_std</th>\n",
              "      <th>event_name</th>\n",
              "      <th>name</th>\n",
              "      <th>fqid</th>\n",
              "      <th>room_fqid</th>\n",
              "      <th>text_fqid</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20090312431273200</th>\n",
              "      <td>0-4</td>\n",
              "      <td>12.180</td>\n",
              "      <td>2.250</td>\n",
              "      <td>11.000733</td>\n",
              "      <td>1.229232</td>\n",
              "      <td>955.5</td>\n",
              "      <td>-1013.5</td>\n",
              "      <td>7.269531</td>\n",
              "      <td>388.166178</td>\n",
              "      <td>416.00</td>\n",
              "      <td>-307.75</td>\n",
              "      <td>-67.50000</td>\n",
              "      <td>126.746080</td>\n",
              "      <td>843.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>424.0</td>\n",
              "      <td>232.526128</td>\n",
              "      <td>639.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>362.25</td>\n",
              "      <td>133.609168</td>\n",
              "      <td>7899.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.854546</td>\n",
              "      <td>842.377807</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>7</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20090312431273200</th>\n",
              "      <td>13-22</td>\n",
              "      <td>14.057</td>\n",
              "      <td>13.637</td>\n",
              "      <td>13.847905</td>\n",
              "      <td>0.122041</td>\n",
              "      <td>1164.0</td>\n",
              "      <td>-1874.0</td>\n",
              "      <td>-121.687500</td>\n",
              "      <td>601.817476</td>\n",
              "      <td>473.25</td>\n",
              "      <td>-849.00</td>\n",
              "      <td>-151.25000</td>\n",
              "      <td>226.191270</td>\n",
              "      <td>859.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>413.0</td>\n",
              "      <td>257.076718</td>\n",
              "      <td>659.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.00</td>\n",
              "      <td>134.654423</td>\n",
              "      <td>4750.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.852383</td>\n",
              "      <td>393.094761</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>12</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20090312431273200</th>\n",
              "      <td>5-12</td>\n",
              "      <td>13.121</td>\n",
              "      <td>12.308</td>\n",
              "      <td>12.759943</td>\n",
              "      <td>0.231607</td>\n",
              "      <td>1111.0</td>\n",
              "      <td>-808.0</td>\n",
              "      <td>12.804688</td>\n",
              "      <td>337.958386</td>\n",
              "      <td>419.50</td>\n",
              "      <td>-331.00</td>\n",
              "      <td>-51.28125</td>\n",
              "      <td>131.170538</td>\n",
              "      <td>872.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>404.5</td>\n",
              "      <td>237.050205</td>\n",
              "      <td>640.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>339.00</td>\n",
              "      <td>162.603835</td>\n",
              "      <td>4183.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.243240</td>\n",
              "      <td>506.186455</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20090312433251036</th>\n",
              "      <td>0-4</td>\n",
              "      <td>12.362</td>\n",
              "      <td>2.250</td>\n",
              "      <td>10.901266</td>\n",
              "      <td>1.601088</td>\n",
              "      <td>934.5</td>\n",
              "      <td>-1112.0</td>\n",
              "      <td>-78.625000</td>\n",
              "      <td>431.685473</td>\n",
              "      <td>441.00</td>\n",
              "      <td>-518.50</td>\n",
              "      <td>-50.18750</td>\n",
              "      <td>151.585043</td>\n",
              "      <td>875.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>259.713553</td>\n",
              "      <td>639.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>346.75</td>\n",
              "      <td>148.604281</td>\n",
              "      <td>5567.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.352516</td>\n",
              "      <td>575.094634</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20090312433251036</th>\n",
              "      <td>13-22</td>\n",
              "      <td>15.155</td>\n",
              "      <td>13.978</td>\n",
              "      <td>14.675087</td>\n",
              "      <td>0.349149</td>\n",
              "      <td>1234.0</td>\n",
              "      <td>-1887.0</td>\n",
              "      <td>-24.750000</td>\n",
              "      <td>475.227565</td>\n",
              "      <td>433.00</td>\n",
              "      <td>-845.00</td>\n",
              "      <td>-115.00000</td>\n",
              "      <td>217.663468</td>\n",
              "      <td>878.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>372.5</td>\n",
              "      <td>296.259769</td>\n",
              "      <td>657.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.25</td>\n",
              "      <td>194.826328</td>\n",
              "      <td>22351.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>139.966843</td>\n",
              "      <td>921.308692</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>73</td>\n",
              "      <td>16</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6dbdec3-af9d-4ff9-807e-e4e6dd0ada31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6dbdec3-af9d-4ff9-807e-e4e6dd0ada31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6dbdec3-af9d-4ff9-807e-e4e6dd0ada31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = feature_engineer(test)\n",
        "print(df_test.shape)\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "hH7D9-GDw9vp",
        "outputId": "92c73267-0267-4069-925d-faf085c0161b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9, 30)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  level_group  elapsed_time_max  elapsed_time_min  \\\n",
              "session_id                                                          \n",
              "20090109393214576         0-4            12.496             2.250   \n",
              "20090109393214576       13-22            15.691            15.564   \n",
              "20090109393214576        5-12            15.520            12.622   \n",
              "20090312143683264         0-4            12.687             2.250   \n",
              "20090312143683264       13-22            14.813            14.331   \n",
              "\n",
              "                   elapsed_time_mean  elapsed_time_std  room_coor_x_max  \\\n",
              "session_id                                                                \n",
              "20090109393214576          11.328029          1.209918       877.958258   \n",
              "20090109393214576          15.633814          0.037125      1214.941972   \n",
              "20090109393214576          13.958909          1.096596      1135.079457   \n",
              "20090312143683264          11.538638          1.205204       945.469667   \n",
              "20090312143683264          14.591751          0.142100      1180.913524   \n",
              "\n",
              "                   room_coor_x_min  room_coor_x_mean  room_coor_x_std  \\\n",
              "session_id                                                              \n",
              "20090109393214576      -941.617960         37.758431       430.614896   \n",
              "20090109393214576     -1911.150867       -116.498761       609.691352   \n",
              "20090109393214576      -952.955767         43.038183       357.332581   \n",
              "20090312143683264      -979.695385         85.958907       426.824981   \n",
              "20090312143683264     -1897.053174        -19.592516       555.144664   \n",
              "\n",
              "                   room_coor_y_max  room_coor_y_min  room_coor_y_mean  \\\n",
              "session_id                                                              \n",
              "20090109393214576       471.968424      -449.577181        -61.855789   \n",
              "20090109393214576       431.237769      -908.325270       -206.340018   \n",
              "20090109393214576       345.257661      -533.748174        -38.659617   \n",
              "20090312143683264       401.948788      -438.390890       -105.585713   \n",
              "20090312143683264       476.424326      -855.716733       -184.339970   \n",
              "\n",
              "                   room_coor_y_std  screen_coor_x_max  screen_coor_x_min  \\\n",
              "session_id                                                                 \n",
              "20090109393214576       142.566482              842.0                0.0   \n",
              "20090109393214576       271.134920              870.0                0.0   \n",
              "20090109393214576       130.030171              874.0                0.0   \n",
              "20090312143683264       173.843856              865.0                0.0   \n",
              "20090312143683264       251.903702              876.0                0.0   \n",
              "\n",
              "                   screen_coor_x_mean  screen_coor_x_std  screen_coor_y_max  \\\n",
              "session_id                                                                    \n",
              "20090109393214576          416.321429         262.870027              639.0   \n",
              "20090109393214576          407.090444         250.700537              657.0   \n",
              "20090109393214576          426.522388         271.931464              652.0   \n",
              "20090312143683264          462.312883         255.147658              632.0   \n",
              "20090312143683264          440.914718         270.851231              653.0   \n",
              "\n",
              "                   screen_coor_y_min  screen_coor_y_mean  screen_coor_y_std  \\\n",
              "session_id                                                                    \n",
              "20090109393214576                0.0          358.542857         131.415502   \n",
              "20090109393214576                0.0          368.139932         152.833905   \n",
              "20090109393214576                0.0          323.835821         158.829195   \n",
              "20090312143683264                0.0          387.760736         167.518005   \n",
              "20090312143683264                0.0          385.352132         171.183773   \n",
              "\n",
              "                   hover_duration_max  hover_duration_min  \\\n",
              "session_id                                                  \n",
              "20090109393214576              5168.0                 0.0   \n",
              "20090109393214576              5533.0                 0.0   \n",
              "20090109393214576             23451.0                 0.0   \n",
              "20090312143683264             15917.0                 0.0   \n",
              "20090312143683264             11249.0                 0.0   \n",
              "\n",
              "                   hover_duration_mean  hover_duration_std  event_name  name  \\\n",
              "session_id                                                                     \n",
              "20090109393214576            71.671429          545.436706          11     4   \n",
              "20090109393214576            61.489761          433.485426          11     4   \n",
              "20090109393214576           244.729478         1502.572245          11     4   \n",
              "20090312143683264           169.319018         1333.020883          11     4   \n",
              "20090312143683264            61.806052          515.814534          11     6   \n",
              "\n",
              "                   fqid  room_fqid  text_fqid  \n",
              "session_id                                     \n",
              "20090109393214576    24          6         13  \n",
              "20090109393214576    52         12         35  \n",
              "20090109393214576    43         12         23  \n",
              "20090312143683264    27          7         15  \n",
              "20090312143683264    55         15         38  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b2e7aab-b8db-4d1c-a84f-f0aff0a35e1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_group</th>\n",
              "      <th>elapsed_time_max</th>\n",
              "      <th>elapsed_time_min</th>\n",
              "      <th>elapsed_time_mean</th>\n",
              "      <th>elapsed_time_std</th>\n",
              "      <th>room_coor_x_max</th>\n",
              "      <th>room_coor_x_min</th>\n",
              "      <th>room_coor_x_mean</th>\n",
              "      <th>room_coor_x_std</th>\n",
              "      <th>room_coor_y_max</th>\n",
              "      <th>room_coor_y_min</th>\n",
              "      <th>room_coor_y_mean</th>\n",
              "      <th>room_coor_y_std</th>\n",
              "      <th>screen_coor_x_max</th>\n",
              "      <th>screen_coor_x_min</th>\n",
              "      <th>screen_coor_x_mean</th>\n",
              "      <th>screen_coor_x_std</th>\n",
              "      <th>screen_coor_y_max</th>\n",
              "      <th>screen_coor_y_min</th>\n",
              "      <th>screen_coor_y_mean</th>\n",
              "      <th>screen_coor_y_std</th>\n",
              "      <th>hover_duration_max</th>\n",
              "      <th>hover_duration_min</th>\n",
              "      <th>hover_duration_mean</th>\n",
              "      <th>hover_duration_std</th>\n",
              "      <th>event_name</th>\n",
              "      <th>name</th>\n",
              "      <th>fqid</th>\n",
              "      <th>room_fqid</th>\n",
              "      <th>text_fqid</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20090109393214576</th>\n",
              "      <td>0-4</td>\n",
              "      <td>12.496</td>\n",
              "      <td>2.250</td>\n",
              "      <td>11.328029</td>\n",
              "      <td>1.209918</td>\n",
              "      <td>877.958258</td>\n",
              "      <td>-941.617960</td>\n",
              "      <td>37.758431</td>\n",
              "      <td>430.614896</td>\n",
              "      <td>471.968424</td>\n",
              "      <td>-449.577181</td>\n",
              "      <td>-61.855789</td>\n",
              "      <td>142.566482</td>\n",
              "      <td>842.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>416.321429</td>\n",
              "      <td>262.870027</td>\n",
              "      <td>639.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>358.542857</td>\n",
              "      <td>131.415502</td>\n",
              "      <td>5168.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.671429</td>\n",
              "      <td>545.436706</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20090109393214576</th>\n",
              "      <td>13-22</td>\n",
              "      <td>15.691</td>\n",
              "      <td>15.564</td>\n",
              "      <td>15.633814</td>\n",
              "      <td>0.037125</td>\n",
              "      <td>1214.941972</td>\n",
              "      <td>-1911.150867</td>\n",
              "      <td>-116.498761</td>\n",
              "      <td>609.691352</td>\n",
              "      <td>431.237769</td>\n",
              "      <td>-908.325270</td>\n",
              "      <td>-206.340018</td>\n",
              "      <td>271.134920</td>\n",
              "      <td>870.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>407.090444</td>\n",
              "      <td>250.700537</td>\n",
              "      <td>657.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>368.139932</td>\n",
              "      <td>152.833905</td>\n",
              "      <td>5533.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>61.489761</td>\n",
              "      <td>433.485426</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>52</td>\n",
              "      <td>12</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20090109393214576</th>\n",
              "      <td>5-12</td>\n",
              "      <td>15.520</td>\n",
              "      <td>12.622</td>\n",
              "      <td>13.958909</td>\n",
              "      <td>1.096596</td>\n",
              "      <td>1135.079457</td>\n",
              "      <td>-952.955767</td>\n",
              "      <td>43.038183</td>\n",
              "      <td>357.332581</td>\n",
              "      <td>345.257661</td>\n",
              "      <td>-533.748174</td>\n",
              "      <td>-38.659617</td>\n",
              "      <td>130.030171</td>\n",
              "      <td>874.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>426.522388</td>\n",
              "      <td>271.931464</td>\n",
              "      <td>652.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>323.835821</td>\n",
              "      <td>158.829195</td>\n",
              "      <td>23451.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>244.729478</td>\n",
              "      <td>1502.572245</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20090312143683264</th>\n",
              "      <td>0-4</td>\n",
              "      <td>12.687</td>\n",
              "      <td>2.250</td>\n",
              "      <td>11.538638</td>\n",
              "      <td>1.205204</td>\n",
              "      <td>945.469667</td>\n",
              "      <td>-979.695385</td>\n",
              "      <td>85.958907</td>\n",
              "      <td>426.824981</td>\n",
              "      <td>401.948788</td>\n",
              "      <td>-438.390890</td>\n",
              "      <td>-105.585713</td>\n",
              "      <td>173.843856</td>\n",
              "      <td>865.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>462.312883</td>\n",
              "      <td>255.147658</td>\n",
              "      <td>632.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>387.760736</td>\n",
              "      <td>167.518005</td>\n",
              "      <td>15917.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>169.319018</td>\n",
              "      <td>1333.020883</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20090312143683264</th>\n",
              "      <td>13-22</td>\n",
              "      <td>14.813</td>\n",
              "      <td>14.331</td>\n",
              "      <td>14.591751</td>\n",
              "      <td>0.142100</td>\n",
              "      <td>1180.913524</td>\n",
              "      <td>-1897.053174</td>\n",
              "      <td>-19.592516</td>\n",
              "      <td>555.144664</td>\n",
              "      <td>476.424326</td>\n",
              "      <td>-855.716733</td>\n",
              "      <td>-184.339970</td>\n",
              "      <td>251.903702</td>\n",
              "      <td>876.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>440.914718</td>\n",
              "      <td>270.851231</td>\n",
              "      <td>653.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>385.352132</td>\n",
              "      <td>171.183773</td>\n",
              "      <td>11249.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>61.806052</td>\n",
              "      <td>515.814534</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>55</td>\n",
              "      <td>15</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b2e7aab-b8db-4d1c-a84f-f0aff0a35e1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b2e7aab-b8db-4d1c-a84f-f0aff0a35e1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b2e7aab-b8db-4d1c-a84f-f0aff0a35e1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES = [c for c in df_train.columns if c != 'level_group']\n",
        "print(FEATURES)\n",
        "ALL_USERS = df_train.index.unique()\n",
        "print(ALL_USERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvhzb0_exWoP",
        "outputId": "12cec1c8-68f7-4410-b8b9-43cb6aad6663"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['elapsed_time_max', 'elapsed_time_min', 'elapsed_time_mean', 'elapsed_time_std', 'room_coor_x_max', 'room_coor_x_min', 'room_coor_x_mean', 'room_coor_x_std', 'room_coor_y_max', 'room_coor_y_min', 'room_coor_y_mean', 'room_coor_y_std', 'screen_coor_x_max', 'screen_coor_x_min', 'screen_coor_x_mean', 'screen_coor_x_std', 'screen_coor_y_max', 'screen_coor_y_min', 'screen_coor_y_mean', 'screen_coor_y_std', 'hover_duration_max', 'hover_duration_min', 'hover_duration_mean', 'hover_duration_std', 'event_name', 'name', 'fqid', 'room_fqid', 'text_fqid']\n",
            "Int64Index([20090312431273200, 20090312433251036, 20090314121766812,\n",
            "            20090314363702160, 20090314441803444, 20090315081004164,\n",
            "            20090315085850788, 20090315101457836, 20090315170769824,\n",
            "            20090317080721164,\n",
            "            ...\n",
            "            22100213081672770, 22100213133089136, 22100215032067016,\n",
            "            22100215190998610, 22100215241104530, 22100215342220508,\n",
            "            22100215460321130, 22100217104993650, 22100219442786200,\n",
            "            22100221145014656],\n",
            "           dtype='int64', name='session_id', length=11779)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#fit"
      ],
      "metadata": {
        "id": "9v4IGcufxWeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_FOLDS = 10\n",
        "\n",
        "gkf = GroupKFold(n_splits=N_FOLDS)\n",
        "oof = pd.DataFrame(data=np.zeros((len(ALL_USERS),18)), index=ALL_USERS)\n",
        "models = {}\n",
        "\n",
        "# COMPUTE CV SCORE WITH N GROUP K FOLD\n",
        "for i, (train_index, test_index) in enumerate(gkf.split(X=df_train, groups=df_train.index)):\n",
        "    print('#'*25)\n",
        "    print('### Fold',i+1)\n",
        "    print('#'*25)\n",
        "    \n",
        "    # ITERATE THRU QUESTIONS 1 THRU 18\n",
        "    for t in range(1,19):\n",
        "        \n",
        "        # USE THIS TRAIN DATA WITH THESE QUESTIONS\n",
        "        if t<=3: grp = \"0-4\"\n",
        "        elif t<=13: grp = \"5-12\"\n",
        "        elif t<=22: grp = \"13-22\"\n",
        "            \n",
        "        # TRAIN DATA\n",
        "        train_x = df_train.iloc[train_index]\n",
        "        train_x = train_x.loc[train_x['level_group'] == grp]\n",
        "        train_users = train_x.index.values\n",
        "        train_y = targets.loc[targets['q']==t].set_index('session').loc[train_users]\n",
        "        \n",
        "        # VALID DATA\n",
        "        valid_x = df_train.iloc[test_index]\n",
        "        valid_x = valid_x.loc[valid_x['level_group'] == grp]\n",
        "        valid_users = valid_x.index.values\n",
        "        valid_y = targets.loc[targets['q']==t].set_index('session').loc[valid_users]\n",
        "        \n",
        "        # TRAIN MODEL\n",
        "        model = LGBMRegressor(learning_rate=0.027, \\\n",
        "                    num_leaves=15, \\\n",
        "                    n_estimators=200, \\\n",
        "                    min_child_samples=20, \\\n",
        "                    boosting_type='gbdt',\n",
        "                    subsample_for_bin=1000,\n",
        "                    max_depth=-1,\n",
        "                    colsample_bytree=0.8)\n",
        "        model.fit(train_x[FEATURES].astype('float32'), train_y['correct'])\n",
        "        \n",
        "        # SAVE MODEL, PREDICT VALID OOF\n",
        "        models[f'{i}_{grp}_{t}'] = model\n",
        "        oof.loc[valid_users, t-1] = model.predict(valid_x[FEATURES])\n",
        "        \n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyR5wfHLxNzM",
        "outputId": "40b6f994-b27b-487b-fcaa-b9cf931453a6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0_0-4_1': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_0-4_2': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_0-4_3': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_5-12_4': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_5-12_5': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_5-12_6': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_5-12_7': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_5-12_8': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_5-12_9': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_5-12_10': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_5-12_11': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_5-12_12': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_5-12_13': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_13-22_14': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_13-22_15': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_13-22_16': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_13-22_17': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '0_13-22_18': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_0-4_1': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_0-4_2': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_0-4_3': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_5-12_4': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_5-12_5': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_5-12_6': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_5-12_7': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_5-12_8': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_5-12_9': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_5-12_10': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_5-12_11': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_5-12_12': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_5-12_13': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_13-22_14': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_13-22_15': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_13-22_16': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_13-22_17': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '1_13-22_18': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_0-4_1': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_0-4_2': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_0-4_3': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_5-12_4': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_5-12_5': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_5-12_6': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_5-12_7': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_5-12_8': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_5-12_9': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_5-12_10': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_5-12_11': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_5-12_12': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_5-12_13': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_13-22_14': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_13-22_15': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_13-22_16': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_13-22_17': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '2_13-22_18': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_0-4_1': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_0-4_2': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_0-4_3': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_5-12_4': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_5-12_5': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_5-12_6': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_5-12_7': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_5-12_8': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_5-12_9': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_5-12_10': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_5-12_11': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_5-12_12': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_5-12_13': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_13-22_14': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_13-22_15': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_13-22_16': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_13-22_17': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '3_13-22_18': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_0-4_1': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_0-4_2': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_0-4_3': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_5-12_4': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_5-12_5': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_5-12_6': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_5-12_7': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_5-12_8': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_5-12_9': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_5-12_10': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_5-12_11': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_5-12_12': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_5-12_13': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_13-22_14': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_13-22_15': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_13-22_16': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_13-22_17': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '4_13-22_18': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_0-4_1': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_0-4_2': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_0-4_3': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_5-12_4': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_5-12_5': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_5-12_6': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_5-12_7': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_5-12_8': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_5-12_9': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_5-12_10': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_5-12_11': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_5-12_12': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_5-12_13': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_13-22_14': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_13-22_15': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_13-22_16': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_13-22_17': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '5_13-22_18': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_0-4_1': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_0-4_2': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_0-4_3': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_5-12_4': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_5-12_5': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_5-12_6': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_5-12_7': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_5-12_8': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_5-12_9': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_5-12_10': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_5-12_11': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_5-12_12': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_5-12_13': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_13-22_14': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_13-22_15': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_13-22_16': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_13-22_17': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '6_13-22_18': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_0-4_1': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_0-4_2': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_0-4_3': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_5-12_4': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_5-12_5': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_5-12_6': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_5-12_7': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_5-12_8': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_5-12_9': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_5-12_10': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_5-12_11': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_5-12_12': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_5-12_13': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_13-22_14': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_13-22_15': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_13-22_16': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_13-22_17': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '7_13-22_18': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_0-4_1': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_0-4_2': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_0-4_3': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_5-12_4': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_5-12_5': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_5-12_6': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_5-12_7': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_5-12_8': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_5-12_9': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_5-12_10': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_5-12_11': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_5-12_12': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_5-12_13': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_13-22_14': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_13-22_15': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_13-22_16': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_13-22_17': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '8_13-22_18': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_0-4_1': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_0-4_2': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_0-4_3': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_5-12_4': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_5-12_5': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_5-12_6': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_5-12_7': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_5-12_8': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_5-12_9': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_5-12_10': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_5-12_11': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_5-12_12': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_5-12_13': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_13-22_14': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_13-22_15': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_13-22_16': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_13-22_17': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000),\n",
              " '9_13-22_18': LGBMRegressor(colsample_bytree=0.8, learning_rate=0.027, n_estimators=200,\n",
              "               num_leaves=15, subsample_for_bin=1000)}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PUT TRUE LABELS INTO DATAFRAME WITH 18 COLUMNS\n",
        "true = oof.copy()\n",
        "for k in range(18):\n",
        "    # GET TRUE LABELS\n",
        "    tmp = targets.loc[targets['q'] == k+1].set_index('session').loc[ALL_USERS]\n",
        "    true[k] = tmp.correct.values"
      ],
      "metadata": {
        "id": "uq6UY_yopYbw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND BEST THRESHOLD TO CONVERT PROBS INTO 1s AND 0s\n",
        "scores = []; thresholds = []\n",
        "best_score = 0; best_threshold = 0\n",
        "\n",
        "for threshold in np.arange(0.4,0.81,0.01):\n",
        "    print(f'{threshold:.02f}, ',end='')\n",
        "    preds = (oof.values.reshape((-1))>threshold).astype('int')\n",
        "    m = f1_score(true.values.reshape((-1)), preds, average='macro')   \n",
        "    scores.append(m)\n",
        "    thresholds.append(threshold)\n",
        "    if m>best_score:\n",
        "        best_score = m\n",
        "        best_threshold = threshold"
      ],
      "metadata": {
        "id": "RHXgWIA1piVu",
        "outputId": "361af7e9-54c7-4dbd-b02e-6544a85b4c97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PLOT THRESHOLD VS. F1_SCORE\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(thresholds,scores,'-o',color='blue')\n",
        "plt.scatter([best_threshold], [best_score], color='blue', s=300, alpha=1)\n",
        "plt.xlabel('Threshold',size=14)\n",
        "plt.ylabel('Validation F1 Score',size=14)\n",
        "plt.title(f'Threshold vs. F1_Score with Best F1_Score = {best_score:.4f} at Best Threshold = {best_threshold:.3}',size=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kKa3yavkpk8I",
        "outputId": "5645c047-a548-4b5b-c171-21ca10680840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(qid,test):\n",
        "    val = 0\n",
        "    if qid<=3: grp = \"0-4\"\n",
        "    elif qid<=13: grp = \"5-12\"\n",
        "    elif qid<=22: grp = \"13-22\"\n",
        "\n",
        "    for fold in range(N_FOLDS): ##10\n",
        "        val += models[f'{fold}_{grp}_{qid}'].predict(test[FEATURES])[0] ##fold->grp_number ,grp->level , qid->question_number\n",
        "    return val > best_threshold*N_FOLDS"
      ],
      "metadata": {
        "id": "YlhUuZ6KqDMp"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = sample_submission.copy()\n",
        "\n",
        "# FEATURE ENGINEER TEST DATA\n",
        "df = feature_engineer(test)\n",
        "#df.shape #(9,30)\n",
        "#sample_submission.shape #(54,4)\n",
        "\n",
        "\n",
        "submission['qid'] = sample_submission['session_id'].apply(lambda x: x.split('_')[1][1:]).astype(int)\n",
        "submission['correct'] = submission['qid'].apply(lambda x: predict(x,df)).astype(int)"
      ],
      "metadata": {
        "id": "VA5GVIZoqDFd",
        "outputId": "3f40f50e-4094-4c21-9bff-284f3994a619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               session_id  correct            session_level  qid\n",
              "0    20090109393214576_q1        0    20090109393214576_0-4    1\n",
              "1    20090312143683264_q1        0    20090312143683264_0-4    1\n",
              "2    20090312331414616_q1        0    20090312331414616_0-4    1\n",
              "3    20090109393214576_q2        1    20090109393214576_0-4    2\n",
              "4    20090312143683264_q2        1    20090312143683264_0-4    2\n",
              "5    20090312331414616_q2        1    20090312331414616_0-4    2\n",
              "6    20090109393214576_q3        1    20090109393214576_0-4    3\n",
              "7    20090312143683264_q3        1    20090312143683264_0-4    3\n",
              "8    20090312331414616_q3        1    20090312331414616_0-4    3\n",
              "9    20090109393214576_q4        0   20090109393214576_5-12    4\n",
              "10   20090312143683264_q4        0   20090312143683264_5-12    4\n",
              "11   20090312331414616_q4        0   20090312331414616_5-12    4\n",
              "12   20090109393214576_q5        0   20090109393214576_5-12    5\n",
              "13   20090312143683264_q5        0   20090312143683264_5-12    5\n",
              "14   20090312331414616_q5        0   20090312331414616_5-12    5\n",
              "15   20090109393214576_q6        1   20090109393214576_5-12    6\n",
              "16   20090312143683264_q6        1   20090312143683264_5-12    6\n",
              "17   20090312331414616_q6        1   20090312331414616_5-12    6\n",
              "18   20090109393214576_q7        1   20090109393214576_5-12    7\n",
              "19   20090312143683264_q7        1   20090312143683264_5-12    7\n",
              "20   20090312331414616_q7        1   20090312331414616_5-12    7\n",
              "21   20090109393214576_q8        1   20090109393214576_5-12    8\n",
              "22   20090312143683264_q8        1   20090312143683264_5-12    8\n",
              "23   20090312331414616_q8        1   20090312331414616_5-12    8\n",
              "24   20090109393214576_q9        1   20090109393214576_5-12    9\n",
              "25   20090312143683264_q9        1   20090312143683264_5-12    9\n",
              "26   20090312331414616_q9        1   20090312331414616_5-12    9\n",
              "27  20090109393214576_q10        1   20090109393214576_5-12   10\n",
              "28  20090312143683264_q10        1   20090312143683264_5-12   10\n",
              "29  20090312331414616_q10        1   20090312331414616_5-12   10\n",
              "30  20090109393214576_q11        1   20090109393214576_5-12   11\n",
              "31  20090312143683264_q11        1   20090312143683264_5-12   11\n",
              "32  20090312331414616_q11        1   20090312331414616_5-12   11\n",
              "33  20090109393214576_q12        1   20090109393214576_5-12   12\n",
              "34  20090312143683264_q12        1   20090312143683264_5-12   12\n",
              "35  20090312331414616_q12        1   20090312331414616_5-12   12\n",
              "36  20090109393214576_q13        1   20090109393214576_5-12   13\n",
              "37  20090312143683264_q13        1   20090312143683264_5-12   13\n",
              "38  20090312331414616_q13        1   20090312331414616_5-12   13\n",
              "39  20090109393214576_q14        1  20090109393214576_13-22   14\n",
              "40  20090312143683264_q14        1  20090312143683264_13-22   14\n",
              "41  20090312331414616_q14        1  20090312331414616_13-22   14\n",
              "42  20090109393214576_q15        0  20090109393214576_13-22   15\n",
              "43  20090312143683264_q15        0  20090312143683264_13-22   15\n",
              "44  20090312331414616_q15        0  20090312331414616_13-22   15\n",
              "45  20090109393214576_q16        1  20090109393214576_13-22   16\n",
              "46  20090312143683264_q16        1  20090312143683264_13-22   16\n",
              "47  20090312331414616_q16        1  20090312331414616_13-22   16\n",
              "48  20090109393214576_q17        1  20090109393214576_13-22   17\n",
              "49  20090312143683264_q17        1  20090312143683264_13-22   17\n",
              "50  20090312331414616_q17        1  20090312331414616_13-22   17\n",
              "51  20090109393214576_q18        1  20090109393214576_13-22   18\n",
              "52  20090312143683264_q18        1  20090312143683264_13-22   18\n",
              "53  20090312331414616_q18        1  20090312331414616_13-22   18"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecd30311-d35b-4d6d-a429-9a787e5ecb75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>correct</th>\n",
              "      <th>session_level</th>\n",
              "      <th>qid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20090109393214576_q1</td>\n",
              "      <td>0</td>\n",
              "      <td>20090109393214576_0-4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20090312143683264_q1</td>\n",
              "      <td>0</td>\n",
              "      <td>20090312143683264_0-4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20090312331414616_q1</td>\n",
              "      <td>0</td>\n",
              "      <td>20090312331414616_0-4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20090109393214576_q2</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_0-4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20090312143683264_q2</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_0-4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20090312331414616_q2</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_0-4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20090109393214576_q3</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_0-4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>20090312143683264_q3</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_0-4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20090312331414616_q3</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_0-4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20090109393214576_q4</td>\n",
              "      <td>0</td>\n",
              "      <td>20090109393214576_5-12</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20090312143683264_q4</td>\n",
              "      <td>0</td>\n",
              "      <td>20090312143683264_5-12</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>20090312331414616_q4</td>\n",
              "      <td>0</td>\n",
              "      <td>20090312331414616_5-12</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>20090109393214576_q5</td>\n",
              "      <td>0</td>\n",
              "      <td>20090109393214576_5-12</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>20090312143683264_q5</td>\n",
              "      <td>0</td>\n",
              "      <td>20090312143683264_5-12</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>20090312331414616_q5</td>\n",
              "      <td>0</td>\n",
              "      <td>20090312331414616_5-12</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>20090109393214576_q6</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_5-12</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>20090312143683264_q6</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_5-12</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>20090312331414616_q6</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_5-12</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>20090109393214576_q7</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_5-12</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20090312143683264_q7</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_5-12</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20090312331414616_q7</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_5-12</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>20090109393214576_q8</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_5-12</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>20090312143683264_q8</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_5-12</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>20090312331414616_q8</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_5-12</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>20090109393214576_q9</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_5-12</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>20090312143683264_q9</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_5-12</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>20090312331414616_q9</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_5-12</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>20090109393214576_q10</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_5-12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>20090312143683264_q10</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_5-12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>20090312331414616_q10</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_5-12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>20090109393214576_q11</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_5-12</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>20090312143683264_q11</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_5-12</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>20090312331414616_q11</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_5-12</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>20090109393214576_q12</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_5-12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>20090312143683264_q12</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_5-12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>20090312331414616_q12</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_5-12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>20090109393214576_q13</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_5-12</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>20090312143683264_q13</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_5-12</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>20090312331414616_q13</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_5-12</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>20090109393214576_q14</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_13-22</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>20090312143683264_q14</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_13-22</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>20090312331414616_q14</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_13-22</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>20090109393214576_q15</td>\n",
              "      <td>0</td>\n",
              "      <td>20090109393214576_13-22</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>20090312143683264_q15</td>\n",
              "      <td>0</td>\n",
              "      <td>20090312143683264_13-22</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>20090312331414616_q15</td>\n",
              "      <td>0</td>\n",
              "      <td>20090312331414616_13-22</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>20090109393214576_q16</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_13-22</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>20090312143683264_q16</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_13-22</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>20090312331414616_q16</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_13-22</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>20090109393214576_q17</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_13-22</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>20090312143683264_q17</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_13-22</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>20090312331414616_q17</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_13-22</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>20090109393214576_q18</td>\n",
              "      <td>1</td>\n",
              "      <td>20090109393214576_13-22</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>20090312143683264_q18</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312143683264_13-22</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>20090312331414616_q18</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312331414616_13-22</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecd30311-d35b-4d6d-a429-9a787e5ecb75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecd30311-d35b-4d6d-a429-9a787e5ecb75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecd30311-d35b-4d6d-a429-9a787e5ecb75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ]
}